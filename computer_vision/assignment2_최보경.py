# -*- coding: utf-8 -*-
"""Assignment2_2016120257_최보경ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ikQ0cy6jXljPXaBM1EqiqdkYnYjsUzT4

## 1. Import packages
"""

# basic package
import scipy.io as spio
import numpy as np

# package for CNN
import torch
import torch.nn as nn
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
import torchvision.datasets

# package for plotting
import matplotlib.pyplot as plt
from bokeh.plotting import figure
from bokeh.io import show
from bokeh.models import LinearAxis, Range1d
from bokeh.plotting import figure, show
from bokeh.io import output_notebook

"""## 2. DataLoader"""

import os
os.chdir(r"/content/drive/My Drive/computer_vision") # inside this folder, all the given dataset exist
os.getcwd()

# read mnist.mat file 
mnist = spio.loadmat('mnist.mat', squeeze_me = True)

# assign to train, text, x, y
train_x = mnist['trainX']
train_y = mnist['trainY'].reshape(60000,1) # reshaping from (1,60000)
test_x = mnist['testX']
test_y = mnist['testY'] 

# check each dataset shape
print(train_x.shape)
print(train_y.shape)
print(test_x.shape)
print(test_y.shape)
print('\n')

# show the input as images
for i in range(10):
  print('label: ',train_y[i])
  plt.imshow(train_x[i].reshape((28, 28)) / 255.0)
  plt.show()

# customize input dataset for the input dataset for torch.utils.data.dataloader
# in the form of 'map-style datasets' having __getitem__() and __len__()

# down-sample
sample_size_train = 6000
sample_size_test = 1000

class TrainData(Dataset):
    def __init__(self): # read the csv
        data = train_x
        gt = train_y
        data = data[:sample_size_train] 
        gt = gt[:sample_size_train]
        self.data = data.reshape(sample_size_train,1,28,28) # reshaped to 4 dimensions
        self.gt = gt 

    def __getitem__(self, index): # read the images, support the indexing such that dataset[i] can be used to get ith sample
        x = self.data[index]
        gt = self.gt[index]
        x = torch.tensor(x) # turn ndarray to tensor 
        gt = torch.tensor(gt)
        return x, gt

    def __len__(self): # return the size of the dataset
        return int(len(self.gt))


class TestData(Dataset):
    def __init__(self): # read the csv 
        data = test_x
        gt = test_y
        data = data[:sample_size_test]
        gt = gt[:sample_size_test]
        self.data = data.reshape(sample_size_test,1,28,28) # reshaped to 4 dimensions
        self.gt = gt

    def __getitem__(self, index):  # read the images, support the indexing such that dataset[i] can be used to get ith sample
        x = self.data[index]
        gt = self.gt[index]
        x = torch.tensor(x) # turn ndarray to tensor
        gt = torch.tensor(gt)
        return x, gt

    def __len__(self): # return the size of the dataset
        return int(len(self.gt))


if __name__ == '__main__':
    trainset = TrainData()
    input_all = trainset.__getitem__(15) # sample one row of the train set
    print(input_all)

"""## 3. Build CNN"""

# set hyperparameters
num_epochs = 30
num_classes = 10 
batch_size = 10
learning_rate = 0.001 # learning rate is set very low, as higher learning rate overshoots the minimum

DATA_PATH = '/content/drive/My Drive/computer_vision'
MODEL_STORE_PATH = '/content/drive/My Drive/computer_vision'

# torch.utils.data.dataloader
train_dataset = TrainData()
test_dataset = TestData()
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, pin_memory = True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, pin_memory = True)

# convolutional neural network (three convolutional layers with ReLU)
class ConvNet(nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer3 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),
            nn.ReLU())  # no pooling at last layer
        self.drop_out = nn.Dropout()
        self.fc1 = nn.Linear(7 * 7 * 128, 1000)
        self.fc2 = nn.Linear(1000, 10)

    def forward(self, x):
        out = self.layer1(x) 
        out = self.layer2(out) 
        out = self.layer3(out)
        out = out.reshape(out.size(0), -1) 
        out = self.drop_out(out)
        out = self.fc1(out)
        out = self.fc2(out)
        return out


model = ConvNet()

# loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# train the model
total_step = len(train_loader)
loss_list = []
acc_list = []
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        # run the forward pass
        outputs = model(images.float()) # change input image data type to float
        labels = torch.squeeze(labels) # need to squeeze the dimension of labels
        labels = labels.long() # and labels data type should be changed to long
        loss = criterion(outputs, labels) 
        loss_list.append(loss.item())

        # backprop and perform Adam optimisation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # track the accuracy
        total = labels.size(0)
        _, predicted = torch.max(outputs.data, 1)
        correct = (predicted == labels).sum().item()
        acc_list.append(correct / total)

        if (i + 1) % 100 == 0:
            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'
                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),
                          (correct / total) * 100))

"""## 4.Evaluate CNN"""

# test the model (validation)
model.eval()

total_step_test = len(test_loader)
loss_test_list = []
acc_test_list = []

with torch.no_grad():
    correct = 0
    total = 0
    for i, (images, labels) in enumerate(test_loader):
        outputs = model(images.float())
        labels = torch.squeeze(labels) 
        labels = labels.long() 

        # track the loss and accuracy
        loss_test = criterion(outputs, labels) 
        loss_test_list.append(loss_test.item())
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        acc_test_list.append(correct / total)

        if (i + 1) % 10 == 0:
            print('Epoch [{}/{}], Step [{}/{}], Validation Loss: {:.4f}, Validation Accuracy: {:.2f}%'
                  .format(epoch + 1, num_epochs, i + 1, total_step_test, loss_test.item(),
                          (correct / total) * 100))

    print('Test Accuracy of the model on the 1000 test images: {} %'.format((correct / total) * 100))

# save the model 
torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')

# plot training loss, accuracy
output_notebook()
print('Average Training Accuracy of the model on the 6000 train images: {} %'.format(( sum(acc_list) / len(acc_list)) * 100))
p = figure(y_axis_label='Loss', width=1500, y_range=(0, 3), title='PyTorch ConvNet results [Train]')
p.extra_y_ranges = {'Accuracy': Range1d(start=0, end=100)}
p.add_layout(LinearAxis(y_range_name='Accuracy', axis_label='Accuracy (%)'), 'right')
p.line(np.arange(len(loss_list)), loss_list)
p.line(np.arange(len(loss_list)), np.array(acc_list) * 100, y_range_name='Accuracy', color='red')
show(p)

# plot testing loss, accuracy
output_notebook()
p = figure(y_axis_label='Loss', width=1500, y_range=(0, 3), title='PyTorch ConvNet results [Test]')
p.extra_y_ranges = {'Accuracy': Range1d(start=0, end=100)}
p.add_layout(LinearAxis(y_range_name='Accuracy', axis_label='Accuracy (%)'), 'right')
p.line(np.arange(len(loss_test_list)), loss_test_list)
p.line(np.arange(len(loss_test_list)), np.array(acc_test_list) * 100, y_range_name='Accuracy', color='red')
show(p)